{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feaf5d11-ab79-4c95-8075-5dcd85f5e442",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/hpe_logo.png\" alt=\"HPE Logo\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0878a8-70b0-47f6-bfc5-b4d8b589cfdc",
   "metadata": {},
   "source": [
    "<h1>Determined.AI - PyTorch Hub Model Porting Activity</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e7304f-8ee1-467e-9e1e-2d3c412364c8",
   "metadata": {},
   "source": [
    "This exercise aims to port a model to run on the HPE Machine Learning Development Environment (Determined.AI) and train it on custom data. We will use a U-Net model for identifying tumors in brain MRI scans. The model is available on the PyTorch Model Hub <a href=\"https://pytorch.org/hub/mateuszbuda_brain-segmentation-pytorch_unet/\">here</a> and was created by mateuszbuda. \n",
    "\n",
    "For the porting, we will use the Determined.AI trial APIs, which will give us access to advanced features such as checkpointing, metrics tracking, distributed training, and hyperparameter search. The below cells provide the code needed to complete the exercise. Please follow the instructions and copy the code blocks to the correct section in the model_def.py and const.yaml files in the experiment folder.\n",
    "\n",
    "<b>Please make sure you only work on your files. Although this is a Jupyter Notebook, you will not be able to execute the code in the cells. Please copy it to the correct files as described.</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50592da7-776e-493b-8e1a-0febfe3023f9",
   "metadata": {},
   "source": [
    "<h2>Introduction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e54252-b0e1-461d-8c32-4f6ad29ed41e",
   "metadata": {},
   "source": [
    "Determined provides a high-level framework APIs for PyTorch, Keras, and Estimators that let users describe their model without boilerplate code. Determined reduces boilerplate by providing a state-of-the-art training loop that provides distributed training, hyperparameter search, automatic mixed precision, reproducibility, and many more features.\n",
    "\n",
    "<h3>Why use Determined.AI?</h3>\n",
    "\n",
    "Running deep learning training workloads can be cumbersome and typically requires a lot of boilerplate code for the training harness.\n",
    "That can include code for distributed training, automatic checkpointing, hyperparameter search and metrics tracking, and compromising hundreds of lines of code.\n",
    "In addition, training a new model (for example, from a public repository) will often require changes to the model code and the training harness, taking up the valuable time of researchers and engineers. \n",
    "\n",
    "Determined.AI can remove the burden of writing and maintaining a custom training harness and offers a streamlined approach to onboard new models to a state-of-the-art training platform, offering the following integrated platform features:\n",
    "\n",
    "<img src=\"./imgs/det_components.jpg\" alt=\"Determined Components\" width=\"900\">\n",
    "\n",
    "<h3>Overview of this workshop</h3>\n",
    "\n",
    "In this activity, we’ll walk through an example and provide helpful hints to organize PyTorch code into Determined’s PyTorchTrial API successfully. Once your code is in the PyTorchTrial format, you can easily take advantage of Determined.AI’s open-source platform.\n",
    "\n",
    "While all codebases are different, code to perform deep learning training tends to follow a typical pattern. Usually, there is a model, optimizer, data, and learning rate scheduler. determined.pytorch.PyTorchTrial follows this pattern to reduce porting friction. To port a model from PyTorch Hub, we will copy the code to load the model to the init method and then define the remaining methods in the template <b>(model_def.py, located in the experiment folder)</b> to get data, train, and validate the model. <b>Below is the current content of the template model_def.py:</b>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0ead53a-4d90-4c68-9c77-e4d348d9981a",
   "metadata": {},
   "source": [
    "import filelock\n",
    "import os\n",
    "from typing import Any, Dict, Sequence, Tuple, Union, cast\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from determined.pytorch import DataLoader, PyTorchTrial, PyTorchTrialContext\n",
    "\n",
    "import data\n",
    "\n",
    "TorchData = Union[Dict[str, torch.Tensor], Sequence[torch.Tensor], torch.Tensor]\n",
    "\n",
    "class MRIUnetTrial(PyTorchTrial):\n",
    "    def __init__(self, context: PyTorchTrialContext) -> None:\n",
    "        self.context = context\n",
    "\n",
    "    def build_training_data_loader(self) -> DataLoader:\n",
    "        return DataLoader()\n",
    "\n",
    "    def build_validation_data_loader(self) -> DataLoader:\n",
    "        return DataLoader()\n",
    "\n",
    "    def train_batch(self, batch: TorchData, epoch_idx: int, batch_idx: int)  -> Dict[str, Any]:\n",
    "        return {}\n",
    "\n",
    "    def evaluate_batch(self, batch: TorchData) -> Dict[str, Any]:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b013c1e-2a8d-41e0-804d-3dc6694a937b",
   "metadata": {},
   "source": [
    "<h2>Step 1: init method in model_def.py</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1984e716-f3e8-4669-aa9d-689f65cc3301",
   "metadata": {},
   "source": [
    "To get started, let's take a look at the code to load the unet model from Pytorch Hub. The original code can also be found <a href=\"https://pytorch.org/hub/mateuszbuda_brain-segmentation-pytorch_unet/\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf97690f-be1d-4a8f-8b2c-52744c1708a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', \n",
    "                       'unet',\n",
    "                       in_channels=3, \n",
    "                       out_channels=1, \n",
    "                       init_features=32, \n",
    "                       pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82833476-b36d-4cff-8a1b-f2ee699ea8a6",
   "metadata": {},
   "source": [
    "As with any Python class, the __init__ method is invoked to construct our trial class. Determined passes this method a single parameter, an instance of PyTorchTrialContext, which inherits from TrialContext. The trial context contains information about the trial, such as the values of the hyperparameters to use for training. All the models and optimizers must be wrapped with wrap_model and wrap_optimizer respectively, which are provided by PyTorchTrialContext. In this PyToch Hub example, we will remove all the parameters and replace them with \"self.context.get_hparam(\"parameter\")\" to retrieve them from the experiment configuration instead of hard coding them. We are also adding some code to load data. For this workshop, data.py is provided, which contains the functions to load our data. Because the init method will be invoked when we load a checkpoint of the model later to make predictions, we will handle the expected error with an exception.\n",
    "\n",
    "Please open the __model_def.py file in the experiments folder__ and copy the below code to the __init__ function in the <b>model_def.py</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43339062-2076-4ec9-a131-f2816dfd83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.config = self.context.get_data_config()\n",
    "\n",
    "# Loading the data sets\n",
    "try:\n",
    "    self.train_dataset, self.val_dataset = data.get_train_val_datasets(self.config[\"data_dir\"],\n",
    "                                                                       self.context.get_hparam(\"split_seed\"),\n",
    "                                                                       self.context.get_hparam(\"validation_ratio\"))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "self.download_directory = torch.hub.get_dir()\n",
    "\n",
    "# Creating directories for download\n",
    "try:\n",
    "    if not os.path.exists(self.download_directory):\n",
    "        os.makedirs(self.download_directory)\n",
    "\n",
    "except:\n",
    "    print(\"Path exists\")\n",
    "\n",
    "with filelock.FileLock(os.path.join(self.download_directory, \"download.lock\")):\n",
    "    model = torch.hub.load(self.config[\"repo\"],\n",
    "                           self.config[\"model\"],\n",
    "                           in_channels=self.context.get_hparam(\"input_channels\"),\n",
    "                           out_channels=self.context.get_hparam(\"output_channels\"),\n",
    "                           init_features=self.context.get_hparam(\"init_features\"),\n",
    "                           pretrained=self.context.get_hparam(\"pretrained\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a2eb2f-0abd-4d1b-b976-a9ea1fe054a0",
   "metadata": {},
   "source": [
    "Then, please __open the const.yaml file ein the experiments folder__ and look for the workspace and project fields. Please replace the placeholders with your workspace name and project name, which you created during the preparation session:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680bb4eb-996b-4249-8243-0a887017e066",
   "metadata": {},
   "source": [
    "workspace: <your_workspace>\n",
    "project: <your_project>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2174a7-e9e0-4087-aa21-548fb64c7fe2",
   "metadata": {},
   "source": [
    "Next, find the data configuration and add the <b>\"repo\" and \"model\"</b> values from the original code above. Your data configuration should then look like this:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7bf7a83-2fab-47cd-95b4-5ad4ffb9527f",
   "metadata": {},
   "source": [
    "data:\n",
    "  data_dir:  '/data/lgg-mri-segmentation/kaggle_3m/'\n",
    "  repo: 'mateuszbuda/brain-segmentation-pytorch'\n",
    "  model: 'unet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d330483f-d868-44d7-98ab-7d4d59f7d7d7",
   "metadata": {},
   "source": [
    "Still in the <b>const.yaml</b> file, find the hyperparameters section, and add <b>\"input_channels\", \"output_channels\", \"init_features\", \"pretrained\" </b> with the values from the original code above. Your hyperparameter configuration should then look like this:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79afb5af-ee6a-48e5-a889-86299527dc83",
   "metadata": {},
   "source": [
    "hyperparameters:\n",
    "  global_batch_size: 64\n",
    "  learning_rate: 0.001\n",
    "  weight_decay: 0.0 \n",
    "  split_seed: 1\n",
    "  validation_ratio: 0.2\n",
    "  num_workers: 2\n",
    "  input_channels: 3\n",
    "  output_channels: 1\n",
    "  init_features: 32\n",
    "  pretrained: false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4b6f12-93e1-4d50-92d0-96c73cdc5513",
   "metadata": {},
   "source": [
    "Back in the in the <b>model_def.py</b>, wrap the model and optimizer as shown below by copying the code to the <b>init</b> method, just below the model definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4d301-f627-4766-86e1-277a84848d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.model = self.context.wrap_model(model)\n",
    "self.optimizer = self.context.wrap_optimizer(optim.Adam(self.model.parameters(),\n",
    "                                                        lr=self.context.get_hparam(\"learning_rate\"),\n",
    "                                                        weight_decay=self.context.get_hparam(\"weight_decay\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5193c3de-316f-4976-871b-4a65df5cf8e6",
   "metadata": {},
   "source": [
    "<h2>Step 2: Custom metric IoU (Intersection over Union)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127bad2f-87c2-4dc2-ad74-62b5744e3a17",
   "metadata": {},
   "source": [
    "Determined allows for any custom training and validation metric to be used. For this use case, IoU (Intersection over Union) is the appropriate metric as it quantifies the degree of overlap between the ground truth and the prediction. To use IoU as our training and validation metric, we <b>define the iou method</b> as shown below and copy it to the <b>model_def.py</b> file. Please make sure that you define it <b>outside of the init method</b> but <b>inside of the MRIUnetTrial class</b>. We will later call the iou method from the train_batch and evaluate_batch methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38a3cc8-a5cf-40ad-ad90-b4e7f9984ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(self, pred, label):\n",
    "    intersection = (pred * label).sum()\n",
    "    union = pred.sum() + label.sum() - intersection\n",
    "    if pred.sum() == 0 and label.sum() == 0:\n",
    "        return 1\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b8e982-0840-44f8-a90a-2b2c2cbf7dda",
   "metadata": {},
   "source": [
    "<h2>Step 3: Data Loaders</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afffb37-348b-4d82-8eaf-dc913473e728",
   "metadata": {},
   "source": [
    "The next two methods we need to define are <b>build_training_data_loader<b> and </b>build_validation_data_loader</b>. Determined uses these methods to load the training and validation datasets, respectively. Both methods should return a determined.pytorch.DataLoader, which is very similar to torch.utils.data.DataLoader. All we have to do is to provide the dataset, the batch size, and define wether we want to shuffle the data. (True for training, false (default) for validation) To ensure scalability, we will also define the number of workers to use for the data loaders. Once again, we set this as a parameter (num_workers) we can get from the const.yaml.\n",
    "\n",
    "Copy the two methods below and place them <b>inside of the MRIUnetTrial class</b> in the <b>model_def.py</b> file. (Note, there is a placeholder for both methods in the model_def.py file. You can replace the placeholders with the below code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c20ca-c25b-4c08-9f42-bd31cfce2b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_training_data_loader(self):\n",
    "    return DataLoader(self.train_dataset, batch_size=self.context.get_per_slot_batch_size(), shuffle=True, num_workers=self.context.get_hparam(\"num_workers\"))\n",
    "\n",
    "def build_validation_data_loader(self):\n",
    "    return DataLoader(self.val_dataset, batch_size=self.context.get_per_slot_batch_size(), num_workers=self.context.get_hparam(\"num_workers\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fd01b4-6d42-494b-9373-593a60b6f5dd",
   "metadata": {},
   "source": [
    "<h2>Step 4: Train Batch</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d948a72-fe0a-4da9-b75f-6599d8dbcf62",
   "metadata": {},
   "source": [
    "With our metric and data in place, we can now move on to training. \n",
    "\n",
    "The train_batch() method is passed a single batch of data from the validation data set; it should run the forward passes on the models, the backward passes on the losses, and step the optimizers. This method should return a dictionary with user-defined training metrics - in this case IoU; Determined will automatically average all the metrics across batches. If an optimizer is set to automatically handle zeroing out the gradients, step_optimizer will zero out the gradients and there will be no need to call optim.zero_grad().\n",
    "\n",
    "<b>The code below does the following:</b>\n",
    "- unpacks our batch in imgs (feature) and masks (labels)\n",
    "- feeds the imgs to the model\n",
    "- calculates the loss (based on the predictions and the labels (masks))\n",
    "- runs the backward pass on the model using the loss \n",
    "- steps the optimizer\n",
    "- calculates the iou training metric \n",
    "- returns the iou metric alongside the loss for the batch\n",
    "\n",
    "Copy the <b>train_batch</b> method below and place it <b>inside of the MRIUnetTrial class</b> in the <b>model_def.py</b> file. (Note, there is a placeholder for the train_batch method in the model_def.py file. You can replace the placeholder with the below code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96f97e2-51b4-422d-b782-bc08c3683b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(self, batch: TorchData, epoch_idx: int, batch_idx: int):\n",
    "    imgs, masks = batch\n",
    "    output = self.model(imgs)\n",
    "    loss = torch.nn.functional.binary_cross_entropy(output, masks)\n",
    "    self.context.backward(loss)\n",
    "    self.context.step_optimizer(self.optimizer)\n",
    "    iou = self.iou((output>0.5).int(), masks)\n",
    "    return {\"loss\": loss, \"IoU\": iou}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511ede4b-7b7e-4ec6-b492-5f16f4e94572",
   "metadata": {},
   "source": [
    "<h2>Step 5: Evaluate Batch</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f5dad2-2f0b-4ff9-925a-82a4d54c7a5f",
   "metadata": {},
   "source": [
    "The evaluate_batch() method is passed a single batch of data from the validation data set; it should compute the user-defined validation metrics on that data (IoU for this example) and return them as a dictionary that maps metric names to values. The metric values for each batch are reduced (aggregated) to produce a single value of each metric for the entire validation set. By default, metric values are averaged, but this behavior can be customized by overriding evaluation_reducer().\n",
    "\n",
    "<b>The code below does the following:</b>\n",
    "- unpacks our batch in imgs (feature) and masks (labels)\n",
    "- feeds the imgs to the model\n",
    "- calculates the validation loss (based on the predictions and the labels (masks))\n",
    "- calculates the iou validation metric \n",
    "- returns the iou metric alongside the loss for the batch\n",
    "\n",
    "Copy the <b>evaluate_batch</b> method below and place it <b>inside of the MRIUnetTrial class</b> in the <b>model_def.py</b> file. (Note, there is a placeholder for the evaluate_batch method in the model_def.py file. You can replace the placeholder with the below code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae21ee85-0fde-4272-a571-094a6dceb856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_batch(self, batch: TorchData):\n",
    "    imgs, masks = batch\n",
    "    output = self.model(imgs)\n",
    "    loss = torch.nn.functional.binary_cross_entropy(output, masks)\n",
    "    iou = self.iou((output>0.5).int(), masks)\n",
    "    return {\"val_loss\": loss, \"val_IoU\": iou}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a18cd9-f56c-49eb-9a32-4bbbb0eb1662",
   "metadata": {},
   "source": [
    "In the <b>const.yaml</b> file, find the searcher section, and <b>change the metric from val_loss to val_IoU</b> to use our custom validation metric we return from the evaluate_batch method."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cdfbc99e-1ddb-4d40-8102-38db4543abf7",
   "metadata": {},
   "source": [
    "searcher:\n",
    "    name: single\n",
    "    metric: val_IoU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e48779e-775d-49b4-9f02-a8f8725a7d57",
   "metadata": {},
   "source": [
    "<h2>Step 6: Final experiment configuration items</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2259a988-6f5d-4078-9d0f-7df7e05e6df1",
   "metadata": {},
   "source": [
    "We are now done working on the model_def.py file. However, we should add a few configuration items to our <b>const.yaml</b> to submit our first experiment. \n",
    "\n",
    "First, let's enable profiling to keep track of the experiment performance and hardware utilization. All we have to do is set <b>profiling enabled to True</b>. Use the code below and add it to your <b>const.yaml</b>. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "8674a057-a1f3-4b98-ab7f-8eb102401efc",
   "metadata": {},
   "source": [
    "profiling:\n",
    "  enabled: True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bddc753-fd8a-47e5-a916-fa7098c94b41",
   "metadata": {},
   "source": [
    "Lastly, let's add the <b>resources</b> section to the <b>const.yaml</b> file and specify the number of slots (GPUs) and the resource pool we will use for this experiment. For this first experiment, please use one (1) slot and specify <b>the resource pool that was assigned to you at the beginning of the workshop.</b> Please copy the below code and paste it to the end of the __const.yaml file and specify the resource pool that was assigned to you.__"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62b31d7b-19b7-4a34-80fd-55e32c7fb6fc",
   "metadata": {},
   "source": [
    "resources:\n",
    "  slots_per_trial: 1\n",
    "  resource_pool: <!!!!YOUR-ASSIGNED-POOL!!!!>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02146232-90f6-47fd-899e-ab9ba26eff68",
   "metadata": {},
   "source": [
    "<h2>Step 7: (Optional) Full model_def.py and const.yaml files for your reference</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1320ed3c-c9bc-438b-b149-6d1e7eb6efd5",
   "metadata": {},
   "source": [
    "In case you have any difficulties with your code (now or going forward), you can copy the full completed model_def.py and const.yaml below to continue with the workshop. <b>Please just make sure to replace the placeholders in const.yaml with your values.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d8bba7-5876-444a-9076-2da70197fcaf",
   "metadata": {},
   "source": [
    "<h3>Reference model_def.py</h3>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "202119f4-3206-4f41-b22b-4bd8afb7f942",
   "metadata": {},
   "source": [
    "import filelock\n",
    "import os\n",
    "from typing import Any, Dict, Sequence, Tuple, Union, cast\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from determined.pytorch import DataLoader, PyTorchTrial, PyTorchTrialContext\n",
    "\n",
    "import data\n",
    "\n",
    "TorchData = Union[Dict[str, torch.Tensor], Sequence[torch.Tensor], torch.Tensor]\n",
    "\n",
    "class MRIUnetTrial(PyTorchTrial):\n",
    "    def __init__(self, context: PyTorchTrialContext) -> None:\n",
    "        self.context = context\n",
    "        self.config = self.context.get_data_config()\n",
    "\n",
    "        # Loading the data sets\n",
    "        try:\n",
    "            self.train_dataset, self.val_dataset = data.get_train_val_datasets(self.config[\"data_dir\"],\n",
    "                                                                               self.context.get_hparam(\"split_seed\"),\n",
    "                                                                               self.context.get_hparam(\"validation_ratio\"))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        self.download_directory = torch.hub.get_dir()\n",
    "\n",
    "        # Creating directories for download\n",
    "        try:\n",
    "            if not os.path.exists(self.download_directory):\n",
    "                os.makedirs(self.download_directory)\n",
    "\n",
    "        except:\n",
    "            print(\"Path exists\")\n",
    "\n",
    "        with filelock.FileLock(os.path.join(self.download_directory, \"download.lock\")):\n",
    "            model = torch.hub.load(self.config[\"repo\"],\n",
    "                                   self.config[\"model\"],\n",
    "                                   in_channels=self.context.get_hparam(\"input_channels\"),\n",
    "                                   out_channels=self.context.get_hparam(\"output_channels\"),\n",
    "                                   init_features=self.context.get_hparam(\"init_features\"),\n",
    "                                   pretrained=self.context.get_hparam(\"pretrained\"))\n",
    "            \n",
    "        self.model = self.context.wrap_model(model)\n",
    "        self.optimizer = self.context.wrap_optimizer(optim.Adam(self.model.parameters(),\n",
    "                                                        lr=self.context.get_hparam(\"learning_rate\"),\n",
    "                                                        weight_decay=self.context.get_hparam(\"weight_decay\")))\n",
    "                                                        \n",
    "        \n",
    "    def build_training_data_loader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.context.get_per_slot_batch_size(), shuffle=True, num_workers=self.context.get_hparam(\"num_workers\"))\n",
    "\n",
    "    def build_validation_data_loader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.context.get_per_slot_batch_size(), num_workers=self.context.get_hparam(\"num_workers\"))\n",
    "\n",
    "    def train_batch(self, batch: TorchData, epoch_idx: int, batch_idx: int):\n",
    "        imgs, masks = batch\n",
    "        output = self.model(imgs)\n",
    "        loss = torch.nn.functional.binary_cross_entropy(output, masks)\n",
    "        self.context.backward(loss)\n",
    "        self.context.step_optimizer(self.optimizer)\n",
    "        iou = self.iou((output>0.5).int(), masks)\n",
    "        return {\"loss\": loss, \"IoU\": iou}\n",
    "\n",
    "    def evaluate_batch(self, batch: TorchData):\n",
    "        imgs, masks = batch\n",
    "        output = self.model(imgs)\n",
    "        loss = torch.nn.functional.binary_cross_entropy(output, masks)\n",
    "        iou = self.iou((output>0.5).int(), masks)\n",
    "        return {\"val_loss\": loss, \"val_IoU\": iou}\n",
    "    \n",
    "    def iou(self, pred, label):\n",
    "        intersection = (pred * label).sum()\n",
    "        union = pred.sum() + label.sum() - intersection\n",
    "        if pred.sum() == 0 and label.sum() == 0:\n",
    "            return 1\n",
    "        return intersection / union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8731503-f5a5-467e-a964-a7415b6ca4a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Reference const.yaml</h3>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bdf8c05c-16a0-4fd2-8423-3e9402008e4f",
   "metadata": {},
   "source": [
    "name: MRI-constant-1GPU\n",
    "workspace: <your_workspace>\n",
    "project: <your_project>\n",
    "description: \"HPE Houston Workshop\"\n",
    "data:\n",
    "  data_dir:  '/data/lgg-mri-segmentation/kaggle_3m/'\n",
    "  repo: 'mateuszbuda/brain-segmentation-pytorch'\n",
    "  model: 'unet'\n",
    "hyperparameters:\n",
    "  global_batch_size: 64\n",
    "  learning_rate: 0.001\n",
    "  weight_decay: 0.0 \n",
    "  split_seed: 1\n",
    "  validation_ratio: 0.2\n",
    "  num_workers: 2\n",
    "  input_channels: 3\n",
    "  output_channels: 1\n",
    "  init_features: 32\n",
    "  pretrained: false\n",
    "records_per_epoch: 3143\n",
    "searcher:\n",
    "    name: single\n",
    "    metric: val_IoU\n",
    "    smaller_is_better: false\n",
    "    max_length:\n",
    "        epochs: 6\n",
    "min_validation_period:\n",
    "   epochs: 1\n",
    "entrypoint: model_def:MRIUnetTrial\n",
    "max_restarts: 5\n",
    "bind_mounts:\n",
    "  - host_path: /mnt/shared_fs/data\n",
    "    container_path: /data\n",
    "    read_only: true\n",
    "environment:\n",
    "  environment_variables:\n",
    "  - GOOGLE_APPLICATION_CREDENTIALS=/run/determined/workdir/shared_fs/misc/gcloud/gcloud.json\n",
    "resources:\n",
    "  slots_per_trial: 1\n",
    "  resource_pool: <your_compute_pool>\n",
    "profiling:\n",
    "  enabled: true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29b915a-ac3e-4365-9256-835baee48374",
   "metadata": {},
   "source": [
    "<h2>Step 8: Launch your first Determined.AI Experiment</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff73f08-1218-4689-82d4-539262360b27",
   "metadata": {},
   "source": [
    "We now have all files and configurations ready to launch the experiment. To do so, we can use the Determined CLI, which has been installed in this Jupyter environment for your convenience. Because the Jupyter Notebook is running on Determined, and we pass the Determined cluster context to the notebook, you can directly interact with the cluster using the CLI without logging in or authenticating.\n",
    "\n",
    "Please <b>execute the below cell</b> to launch the const.yaml experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02706a9c-2c5e-41eb-99f8-b6008c566028",
   "metadata": {},
   "outputs": [],
   "source": [
    "!det e create ./experiments/const.yaml ./experiments/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba2cd12-ed1e-4744-b0cf-b8e218cdcdcf",
   "metadata": {},
   "source": [
    "Up <b>here ^</b>, you should see a confirmation saying that the experiment has been created. Switch back to the Determined.AI WebGUI, and browse to your workspace/project to find your experiment. You can observe the training and validation metrics, the checkpoints, the profiling, and the experiment logs as it runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a99bcc3-c95b-451c-99e5-c953d654a39a",
   "metadata": {},
   "source": [
    "<h2>Step 9: Launch a distributed training Experiment</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1953d3e6-16e1-4d37-93f1-bd48910b1064",
   "metadata": {},
   "source": [
    "With Determined, going from a single GPU training job to a multi-GPU distributed training job is as easy as changing a simple configuration line. There is no need to worry about setting up frameworks like Horovod or PyTorch Lightning.\n",
    "\n",
    "Let's copy the <b>const.yaml</b> file and name the copy <b>distributed.yaml</b>. Open the <b>distributed.yaml</b> file. First, look for the name field and <b>change it from MRI-constant-1GPU to MRI-constant-GPU2</b> to indicate the distributed training job. Then, look for the resources section. Change the <b>slots_per_trial field from 1 to 2</b> to run a distributed training job on 2 GPUs. Save the file and <b>execute the below cell.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe2278-bad6-4a61-aa47-e76c182e9e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!det e create ./experiments/distributed.yaml ./experiments/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d86894-098b-4073-af3e-c75adfedbcae",
   "metadata": {},
   "source": [
    "Up <b>here ^</b>, you should see a confirmation saying that the experiment has been created. Switch back to the Determined.AI WebGUI, and browse your workspace/project to find your experiment. You can observe the training and validation metrics, the checkpoints, the profiling, and the experiment logs as it runs. <b>Notice how you can see the four GPUs in the Profiler tab, and the different ranks in the Logs tab.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d429738b-11fa-45da-86dd-b5159f3da4f1",
   "metadata": {},
   "source": [
    "<h2>Step 10: Launch a hyperparameter search experiment</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55df2936-cb2c-4a46-8a0d-19e5d263fd16",
   "metadata": {},
   "source": [
    "The first step toward automatic hyperparameter tuning is to define the hyperparameter space, e.g., by listing the decisions that may impact model performance. We can specify a range of possible values in the experiment configuration for each hyperparameter in the search space.\n",
    "\n",
    "To do this, copy the <b>distributed.yaml</b> file and name the copy <b>adaptive.yaml</b>. Open the <b>adaptive.yaml</b> file, change the <b>name from MRI-constant-2GPU to MRI-adaptive-1GPU </b> and then look for the hyperparameters section. In that section, we have to change the static hyperparameter values to ranges and specify the type (int, double, log, categorical). You can use the configuration in the below cell as a starting point. Copy the hyperparameter section from the cell below and use it to replace the hyperparameter section in your <b>adaptive.yaml</b>."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a77bde80-13d2-455b-a94a-47256e968786",
   "metadata": {},
   "source": [
    "hyperparameters:\n",
    "  global_batch_size: 64\n",
    "  learning_rate:\n",
    "    type: log\n",
    "    minval: -5\n",
    "    maxval: -1\n",
    "    base: 10\n",
    "  weight_decay:\n",
    "    type: log\n",
    "    minval: -8\n",
    "    maxval: -3\n",
    "    base: 10\n",
    "  split_seed: 1\n",
    "  validation_ratio: 0.2\n",
    "  num_workers: 2\n",
    "  input_channels: 3\n",
    "  output_channels: 1\n",
    "  init_features: 32\n",
    "  pretrained: false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5c53cf-9903-4195-8563-50e227238d05",
   "metadata": {},
   "source": [
    "To tell the Determined.AI master that we want to search over the defined hyperparameter space, we have to <b>change the searcher from single to adaptive_asha</b>, which is the state-of-the-art search algorithm implementing early stopping. We will also tell Determined how many different combinations we would like to explore. Please make sure that the searcher name and max_trials are specified as below in your adaptive.yaml file under searcher:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e60c8c12-d4e9-4203-b629-957fd96b7e68",
   "metadata": {},
   "source": [
    "searcher:\n",
    "    name: adaptive_asha\n",
    "    max_trials: 7\n",
    "    metric: val_IoU\n",
    "    smaller_is_better: false\n",
    "    max_length:\n",
    "        epochs: 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7a28b5-30d1-4509-a974-37869e20947d",
   "metadata": {},
   "source": [
    "Because we are using a shared cluster with all the workshop participants, please <b>change the slots_per_trial value from 2 to 1</b>, as otherwise you would be requesting 14 GPUs just for your experiment alone.<br>\n",
    "Below is the correct resources section for this experiment. You can copy it and simply specify your compute pool again."
   ]
  },
  {
   "cell_type": "raw",
   "id": "73590f21-0af7-4eb5-b198-eeeae1a71583",
   "metadata": {},
   "source": [
    "resources:\n",
    "  slots_per_trial: 1\n",
    "  resource_pool: <your_compute_pool>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7bfacf-5bdb-4d4f-95e8-a0cfb7c18ebb",
   "metadata": {},
   "source": [
    "Save the file and <b>execute the below cell to run the experiment. Please note the experiment ID as you will need it for the next exercise.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a572c0-3dcc-40e9-9bdb-a41be750f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!det e create ./experiments/adaptive.yaml ./experiments/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee156a0-e54c-4870-8571-a964cddea169",
   "metadata": {},
   "source": [
    "Up <b>here ^</b>, you should see a confirmation saying that the experiment has been created. Switch back to the Determined.AI WebGUI, and browse to your workspace/project to find your experiment. <b>Please note the experiment ID for the next exercise</b>\n",
    "\n",
    "<b>Notice how the experiment overview changed.</b> You now have a new tab in the experiment overview called \"Trials\". Each trial represents a chosen combination of Hyperparameters. Under \"Visualization,\" you can see different plots showing how the various trials are doing relative to each other and any potential between the Hyperparemters. If you want to look at a specific trial, you can click on it and see particular information (Overview, chosen Hyperparameters, Profiler, Logs, etc.) of that trial.\n",
    "\n",
    "<b>Notice how poorly performing trials are getting stopped.</b> Determined.AI uses the state-of-the-art adaptive ASHA algorithm based on Hyperband. It implements the principle of early stopping and terminating trials (HP combinations) that are doing poorly while extending trials that are doing well. Determined can optimize resource utilization vs. time vs. exploited hyperparameter space. For more details on adaptive ASHA visit our documentation <a href=\"https://docs.determined.ai/latest/training/hyperparameter/search-methods/hp-adaptive-asha.html?highlight=adaptive%20asha\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f23f4-dd57-4eb1-9be9-295a516c3490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
